{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-ray Enhancement AI - Training Demo\n",
    "\n",
    "This notebook demonstrates how to train the UNet + Attention + GAN model for X-ray image enhancement.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run this notebook in Google Colab for free GPU access!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check GPU availability\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPyTorch version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCUDA available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/yourusername/xray-healthcare-ai.git\n",
    "%cd xray-healthcare-ai\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r backend/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset\n",
    "\n",
    "You can use NIH ChestX-ray14 or any chest X-ray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload from local\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Download from Kaggle\n",
    "# First, upload your kaggle.json API key\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "uploaded = files.upload()  # Upload kaggle.json\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download dataset\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "!unzip chest-xray-pneumonia.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data/train', exist_ok=True)\n",
    "os.makedirs('data/val', exist_ok=True)\n",
    "\n",
    "# Check dataset structure\n",
    "!ls -la data/\n",
    "\n",
    "# Copy/move files to train and val directories\n",
    "# (Adjust based on your dataset structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.gan import Pix2PixGAN\n",
    "\n",
    "# Create model\n",
    "model = Pix2PixGAN(in_channels=1, out_channels=1)\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(1, 1, 256, 256)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    x = x.cuda()\n",
    "\n",
    "output = model.generate(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.generator.parameters())\n",
    "print(f\"Generator parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.dataset import XRayDataset, get_training_augmentation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create dataset\n",
    "dataset = XRayDataset(\n",
    "    image_dir='data/train',\n",
    "    transform=get_training_augmentation(),\n",
    "    img_size=256,\n",
    "    degradation_level=0.5\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Visualize sample\n",
    "sample = dataset[0]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(sample['degraded'].squeeze(), cmap='gray')\n",
    "axes[0].set_title('Degraded')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(sample['clean'].squeeze(), cmap='gray')\n",
    "axes[1].set_title('Clean')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to training directory\n",
    "%cd training\n",
    "\n",
    "# Run training script\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "import torch\n",
    "from models.gan import Pix2PixGAN\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Pix2PixGAN(in_channels=1, out_channels=1)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoints/best_model.pth', map_location=device)\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Best PSNR: {checkpoint['best_psnr']:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image\n",
    "from training.dataset import XRayDataset\n",
    "\n",
    "dataset = XRayDataset('data/val', img_size=256, degradation_level=0.5)\n",
    "sample = dataset[0]\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    degraded = sample['degraded'].unsqueeze(0).to(device)\n",
    "    enhanced = model.generate(degraded)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axes[0].imshow(sample['degraded'].squeeze().cpu(), cmap='gray')\n",
    "axes[0].set_title('Degraded Input')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(enhanced.squeeze().cpu(), cmap='gray')\n",
    "axes[1].set_title('Enhanced Output')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sample['clean'].squeeze().cpu(), cmap='gray')\n",
    "axes[2].set_title('Ground Truth')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.metrics import calculate_psnr, calculate_ssim\n",
    "\n",
    "# Calculate metrics\n",
    "psnr = calculate_psnr(enhanced.cpu(), sample['clean'].unsqueeze(0))\n",
    "ssim = calculate_ssim(enhanced.cpu(), sample['clean'].unsqueeze(0))\n",
    "\n",
    "print(f\"PSNR: {psnr:.2f} dB\")\n",
    "print(f\"SSIM: {ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download to local machine\n",
    "from google.colab import files\n",
    "files.download('checkpoints/best_model.pth')\n",
    "\n",
    "# Or save to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import shutil\n",
    "shutil.copy('checkpoints/best_model.pth', '/content/drive/MyDrive/xray_model.pth')\n",
    "print(\"Model saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download the model** and use it in the web application\n",
    "2. **Experiment with hyperparameters** in `training/train.py`\n",
    "3. **Try different datasets** for specialized applications\n",
    "4. **Deploy the model** using the FastAPI backend\n",
    "\n",
    "Happy training! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
